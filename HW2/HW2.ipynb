{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io  # Using scikit-image to process image\n",
    "from enum import Enum\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(Enum):\n",
    "    num_hidden = 1024\n",
    "    num_component = 2\n",
    "    learning_rate = 0.1\n",
    "    random_seed = 0\n",
    "    epoch = 64\n",
    "\n",
    "\n",
    "class ImageType(Enum):\n",
    "    Carambula = 0\n",
    "    Lychee = 1\n",
    "    Pear = 2\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(Config.random_seed.value)\n",
    "pca = PCA(n_components=Config.num_component.value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image & reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, dir, split) -> None:\n",
    "        self.split = split\n",
    "        self.dir = os.path.join(\n",
    "            dir, \"Data_train\" if split == \"train\" else \"Data_test\"\n",
    "        )\n",
    "\n",
    "        self.labels = np.empty(0, dtype=np.int32)\n",
    "\n",
    "        for index in ImageType:\n",
    "            images_path = os.path.join(self.dir, index.name, \"*.png\")\n",
    "            images = io.imread_collection(images_path).concatenate() / 255\n",
    "\n",
    "            try:\n",
    "                self.images = np.concatenate((self.images, images))\n",
    "            except AttributeError:\n",
    "                self.images = images\n",
    "\n",
    "            self.labels = np.concatenate(\n",
    "                (\n",
    "                    self.labels,\n",
    "                    np.full(images.shape[0], index.value, dtype=np.int32),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.images_pca = self.__get_PCA_images()\n",
    "\n",
    "    def __get_PCA_images(self):\n",
    "        self.images_reshape = self.images.reshape(self.images.shape[0], -1)\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            return pca.fit_transform(self.images_reshape)\n",
    "        else:\n",
    "            return pca.transform(self.images_reshape)\n",
    "\n",
    "    def get(self):\n",
    "        return self.images_pca, self.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = ImageLoader(\".\", \"train\").get()\n",
    "test_x, test_y = ImageLoader(\".\", \"test\").get()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, size: list) -> None:\n",
    "        self.size = size\n",
    "        self.num_layer = len(size)\n",
    "\n",
    "        self.bias = [rng.random((i, 1)) for i in size[1:]]\n",
    "        self.weights = [rng.random((j, k)) for k, j in zip(size[:-1], size[1:])]\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / sum(np.exp(x))\n",
    "\n",
    "    def cost_derivative(self, label, pred):\n",
    "        cost = 0\n",
    "        for i, output in enumerate(pred):\n",
    "            if i == label:\n",
    "                cost += output - 1\n",
    "            else:\n",
    "                cost += output\n",
    "        return cost\n",
    "\n",
    "    def dim_increase(self, x):\n",
    "        return x.reshape(-1, 1)\n",
    "\n",
    "    def __feed_forward(self, feature: np.ndarray) -> np.ndarray:\n",
    "        # Initial declare the variable\n",
    "        activation = feature\n",
    "        activations = [activation]\n",
    "        zs = []\n",
    "\n",
    "        # Hidden layer\n",
    "        for b, w in zip(self.bias, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            activation = self.sigmoid(z)\n",
    "\n",
    "            zs.append(z)\n",
    "            activations.append(activation)\n",
    "\n",
    "        # Output layer\n",
    "        activations[-1] = self.softmax(activations[-1])\n",
    "\n",
    "        return zs, activations\n",
    "\n",
    "    def __back_propagation(self, feature, label, learning_rate):\n",
    "        zs, activations = self.__feed_forward(feature)\n",
    "        weight_gradient = [np.zeros(w.shape) for w in self.weights]\n",
    "        bias_gradient = [np.zeros(b.shape) for b in self.bias]\n",
    "\n",
    "        delta = self.cost_derivative(\n",
    "            label, activations[-1]\n",
    "        ) * self.sigmoid_derivative(zs[-1])\n",
    "\n",
    "        bias_gradient[-1] = delta\n",
    "        weight_gradient[-1] = np.dot(delta, activations[-2].T)\n",
    "\n",
    "        for l in range(2, self.num_layer):\n",
    "            delta = np.dot(\n",
    "                self.weights[-l + 1].T, delta\n",
    "            ) * self.sigmoid_derivative(zs[-l])\n",
    "\n",
    "            bias_gradient[-l] = delta\n",
    "            weight_gradient[-l] = np.dot(delta, activations[-l - 1].T)\n",
    "\n",
    "        return bias_gradient, weight_gradient\n",
    "\n",
    "    def train(self, features, labels, learning_rate, epoch):\n",
    "        for _ in range(epoch):\n",
    "            features_shuffle = rng.permutation(features)\n",
    "            for label, feature in zip(labels, features_shuffle):\n",
    "                bias_gradient, weight_gradient = self.__back_propagation(\n",
    "                    self.dim_increase(feature), label, learning_rate\n",
    "                )\n",
    "\n",
    "                self.bias = [\n",
    "                    b - learning_rate * b_gradient\n",
    "                    for b, b_gradient in zip(self.bias, bias_gradient)\n",
    "                ]\n",
    "\n",
    "                self.weights = [\n",
    "                    w - learning_rate * w_gradient\n",
    "                    for w, w_gradient in zip(self.weights, weight_gradient)\n",
    "                ]\n",
    "\n",
    "    def pred(self, test_features):\n",
    "        test_result = [\n",
    "            np.argmax(self.__feed_forward(self.dim_increase(feature))[1][-1])\n",
    "            for feature in test_features\n",
    "        ]\n",
    "\n",
    "        return test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(\n",
    "    [Config.num_component.value, Config.num_hidden.value, len(ImageType)]\n",
    ")\n",
    "model.train(train_x, train_y, Config.learning_rate.value, Config.epoch.value)\n",
    "pred_y = model.pred(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def evaluate(pred_y, test_y):\n",
    "    corr = 0\n",
    "    for pred, test in zip(pred_y, test_y):\n",
    "        if pred == test:\n",
    "            corr += 1\n",
    "\n",
    "    return corr / len(pred_y)\n",
    "\n",
    "\n",
    "print(evaluate(pred_y, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rng_int(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.integers(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng_int(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
